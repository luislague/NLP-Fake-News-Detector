{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "This notebook loads and explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q textblob\n",
    "!python -m textblob.download_corpora\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from random import randint\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "separator = 100 * '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup csv file\n",
    "Some rows have multiple text headers separated as tabs, which are treated as multiple columns when loaded into a dataframe.  \n",
    "We run a cleaning pass on the csv file and  merge them to get only one text per row  \n",
    "**[label TAB text]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cleaned and filtered. Saved as training_data_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def clean_tabs_and_filter_csv(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        writer = csv.writer(outfile, delimiter='\\t')\n",
    "        \n",
    "        for row in reader:\n",
    "            if len(row) >= 2:\n",
    "                # The first tab separates the label from the text, keep that.\n",
    "                label = row[0]\n",
    "                text = row[1]\n",
    "                \n",
    "                # Replace tabs in the text part with spaces\n",
    "                clean_text = text.replace('\\t', ' ')\n",
    "                \n",
    "                # Write the cleaned row to the new file\n",
    "                writer.writerow([label, clean_text])\n",
    "\n",
    "# Usage\n",
    "input_file = 'training_data_lowercase.csv'\n",
    "output_file = 'training_data_clean.csv'\n",
    "\n",
    "clean_tabs_and_filter_csv(input_file, output_file)\n",
    "\n",
    "print(\"File cleaned and filtered. Saved as\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34152, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year‚Ä...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama‚Äôs Nam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Duri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Racist Alabama Cops Brutalize Black Boy While ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fresh Off The Golf Course</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trump Said Some INSANELY Racist Stuff Inside T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Former CIA Director Slams Trump Over UN Bullying</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WATCH: Brand-New Pro-Trump Ad Features So Much...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Donald Trump Sends Out Embarrassing New Year‚Ä...      0\n",
       "1  Drunk Bragging Trump Staffer Started Russian C...      0\n",
       "2  Sheriff David Clarke Becomes An Internet Joke ...      0\n",
       "3  Trump Is So Obsessed He Even Has Obama‚Äôs Nam...      0\n",
       "4  Pope Francis Just Called Out Donald Trump Duri...      0\n",
       "5  Racist Alabama Cops Brutalize Black Boy While ...      0\n",
       "6                          Fresh Off The Golf Course      0\n",
       "7  Trump Said Some INSANELY Racist Stuff Inside T...      0\n",
       "8   Former CIA Director Slams Trump Over UN Bullying      0\n",
       "9  WATCH: Brand-New Pro-Trump Ad Features So Much...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# file_path = \"../data/TRAINING_DATA.txt\"\n",
    "file_path = \"training_data_lowercase.csv\"\n",
    "data = pd.read_csv(file_path, sep='\\t', header=None, names=['label', 'text'])\n",
    "data = data[['text', 'label']]\n",
    "print(data.shape)\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "[1904] Ver El Teen Mom Cuelgue Con Su Hija y fiesta con sus amigas AQUÍ ! --> 0\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = data[\"text\"]\n",
    "y = data[\"label\"]\n",
    "\n",
    "def print_text(feature, label, idx=None):\n",
    "    try:\n",
    "        print(separator)\n",
    "        if idx is None:\n",
    "            idx = randint(0, feature.shape[0])\n",
    "        print(f\"[{idx}]\", feature[idx], \"-->\", label[idx])\n",
    "        print(separator)\n",
    "    except:\n",
    "        print(\"Can't print email contents.\")\n",
    "\n",
    "print_text(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning/Preprocessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "[11374] Eso es algo que quiero decir muy bruscamente justo al principio . --> 1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[11374] eso es algo que quiero decir muy bruscamente justo al principio --> 1\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^A-Za-zÁÉÍÓÚáéíóúÑñ\\s]', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Substitute multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# apply cleaning\n",
    "X_clean = X.apply(clean_text)\n",
    "\n",
    "idx = randint(0, len(X))\n",
    "print_text(X, y, idx)\n",
    "print_text(X_clean, y, idx)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 spanish stopwords\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[9250] En las palabras inmortales del patriota escocés Mel Gibson , \" usted puede tomar sus vidas , pero nunca tomar sus pompones ! --> 1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[9250] palabras inmortales patriota escocés mel gibson usted puede tomar vidas nunca tomar pompones --> 1\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "stopwords_sp = stopwords.words(\"spanish\")\n",
    "print(len(stopwords_sp), \"spanish stopwords\")  # 313 stopwords for the spanish language\n",
    "\n",
    "def remove_stopwords(text):\n",
    "\n",
    "    # tokenize the text by splitting on spaces\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stopwords_sp]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# apply removing stopwords\n",
    "X_clean = X_clean.apply(remove_stopwords)\n",
    "\n",
    "# check results\n",
    "idx = randint(0, len(X))\n",
    "print_text(X, y, idx)\n",
    "print_text(X_clean, y, idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10446,) (10446,)\n",
      "(4478,) (4478,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y, test_size=0.3, random_state=42, stratify=data['label'])\n",
    "\n",
    "# reset indexes\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# print shapes\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
